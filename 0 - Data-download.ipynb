{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Data download\n",
    "\n",
    "Before testing out the notebooks, we need some data. The data will be available from the [4TU center for research data](https://data.4tu.nl/repository/). The data is available as [10.4121/uuid:7f672638-66f6-4ec3-a16c-34181cc45202](https://data.4tu.nl/repository/uuid:7f672638-66f6-4ec3-a16c-34181cc45202). It can be accessed using [OPeNDAP](https://researchdata.4tu.nl/en/use-4turesearchdata/opendap-and-netcdf/), enabling realtime interaction without full download of the data.\n",
    "However, it can be beneficial to create a local copy of the data. This Notebook does exactly this using `xarray`. \n",
    "\n",
    "The **total** dataset containing both Bright Field and Dark Field spectroscopic data and for each the raw data, detector corrected data and driftcorrected is about **9.87 GiB**, and it is **not recommended** to download everything. \n",
    "\n",
    "The corrected data can be generated locally and is only recommended for download if you plan to not run the detector correction or image registration notebooks.\n",
    "\n",
    "Finally, it is possible to use only a reduced landing energy range, to reduce download size and computation load. Suitable ranges are suggested below.\n",
    "\n",
    "But first, let's import some useful packages and define the dataset location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opendap_location =  'https://opendap.tudelft.nl/thredds/dodsC/data2/uuid'\n",
    "dataset_UUID = '7f672638-66f6-4ec3-a16c-34181cc45202'\n",
    "save_folder = './data'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Bright Field  & Dark Field dataset\n",
    "The cell below downloads the bright field and/or dark field datasets. If you don't look to run the detector correction notebook or the drift correction, add the respective suffix.\n",
    "\n",
    "The reduced energy range focuses on the layer counts and reduces the download size from **>1.5 GiB** to  **<90 MiB** per dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "         '20171120_160356_3.5um_591.4_IVhdr', \n",
    "         '20171120_215555_3.5um_583.1_IVhdr_DF2'\n",
    "        ]\n",
    "#suffix = ''\n",
    "#suffix = '_detectorcorrected'  # Needed for benchmarking and image registration\n",
    "suffix = '_driftcorrected'  # Fully corrected data, used for dimension reduction and clustering\n",
    "\n",
    "# Reduced BF range from 0 to 5 eV in 0.2 eV steps, DF range from ... to ...\n",
    "red_ranges = [slice(42,92,2) , slice(42,92,2)]\n",
    "for i, name in enumerate(names):\n",
    "    location = os.path.join(opendap_location, dataset_UUID, name + suffix + '.nc')\n",
    "    data = xr.open_dataset(location)\n",
    "    if red_ranges:\n",
    "        data = data.isel(time=red_ranges[i])\n",
    "    data.to_netcdf(os.path.join(save_folder,\n",
    "                                name + suffix + '.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Detector Correction\n",
    "\n",
    "The cell below downloads all additional data needed for the Detector Correction notebook, providing Dark Count data and HDR calibration curves for the ESCHER setup. \n",
    "\n",
    "Total download size **~ 600 MiB**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['20171205_115846_0.66um_475.8_DC',\n",
    "         '20171205_100540_0.66um_479.2_sweepCHANNELPLATE_SET_lowintensity_v2',\n",
    "         '20171205_103440_0.66um_479.2_sweepCHANNELPLATE_SET_highintensity',\n",
    "         '20171205_143305_31um_474.2_sweepCHANNELPLATE_SET_higherintensity',\n",
    "         '20190509_155656_3.5um_562.1_IV_BILAYER',\n",
    "         '20190509_142203_3.5um_561.5_IVhdr_BILAYER']\n",
    "for name in names:\n",
    "    location = os.path.join(opendap_location, dataset_UUID, name + '.nc')\n",
    "    data = xr.open_dataset(location)\n",
    "    data.to_netcdf(os.path.join(save_folder,\n",
    "                                name + '.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Benchmark reference\n",
    "The cells below downloads the reference results for Accureacy testing and Benchmarking notebooks. As the full parameter range of these notebooks takes **days** to compute on 2019's hardware, the download of **< 4 MiB** is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                        (i: 5, sigma: 6, strides: 15, t: 5)\n",
       "Coordinates:\n",
       "  * t                              (t) int32 0 1 2 3 4\n",
       "  * sigma                          (sigma) int32 3 7 9 11 13 17\n",
       "  * i                              (i) int32 0 1 2 3 4\n",
       "  * strides                        (strides) int32 15 20 35 50 70 ... 5 4 3 2 1\n",
       "Data variables:\n",
       "    __xarray_dataarray_variable__  (i, sigma, strides, t) float64 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'benchmarkresult_reference'\n",
    "location = os.path.join(opendap_location, dataset_UUID, name + '.nc')\n",
    "data = xr.open_dataset(location)\n",
    "data.to_netcdf(os.path.join(save_folder, name + '.nc'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (A: 40, direction: 2, n: 100, s: 55)\n",
       "Coordinates:\n",
       "  * s          (s) float64 0.0 0.2 0.4 0.6 0.8 1.0 ... 10.0 10.2 10.4 10.6 10.8\n",
       "  * n          (n) int32 0 1 2 3 4 5 6 7 8 9 ... 90 91 92 93 94 95 96 97 98 99\n",
       "  * A          (A) float64 0.0 0.05 0.1 0.15 0.2 0.25 ... 1.75 1.8 1.85 1.9 1.95\n",
       "  * direction  (direction) <U1 'x' 'y'\n",
       "Data variables:\n",
       "    shift      (direction, A, s, n) float64 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'accuracy_result_reference'\n",
    "location = os.path.join(opendap_location, dataset_UUID, name + '.nc')\n",
    "data = xr.open_dataset(location)\n",
    "# We need to replace the string dtype for a proper unicode string\n",
    "data = data.assign_coords(direction=np.char.decode(data.direction.data))\n",
    "data.to_netcdf(os.path.join(save_folder, name + '.nc'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
